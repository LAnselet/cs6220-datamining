{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jvgw4ZBj-rvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaqASVBt-W_O"
      },
      "outputs": [],
      "source": [
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/movie_titles.csv\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/combined_data_1.txt\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/combined_data_2.txt\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/combined_data_3.txt\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/combined_data_4.txt\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/basket_data.csv\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/probe.txt\n",
        "# !wget https://course.ccs.neu.edu/cs6220/fall2023/homework-1/netflix-data/qualifying.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Review"
      ],
      "metadata": {
        "id": "Ec5Leib6_3Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. What is the cardinality in \"basket_data.csv\"?\n",
        "\n",
        "import csv\n",
        "\n",
        "item_set = set()\n",
        "\n",
        "def cardinality_items(filename):\n",
        "  '''\n",
        "  Takes a filename \"*.csv\" and returns and\n",
        "  interger\n",
        "  '''\n",
        "  with open(filename) as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      for item in row:\n",
        "        item_set.add(item.strip())\n",
        "\n",
        "  return len(item_set)\n",
        "\n",
        "cardinality_items(\"/content/basket_data.csv\")"
      ],
      "metadata": {
        "id": "ZNH_rYH0_6bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e12b1d-baea-4eda-fab3-ed03b369d8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. output a list of all possible unique itemsets with non-repeating k items\n",
        "\n",
        "def all_itemsets(items, k):\n",
        "    result = [[]]\n",
        "\n",
        "    for item in items:\n",
        "        result += [current + [item] for current in result]\n",
        "\n",
        "    return [comb for comb in result if len(comb) == k]\n",
        "\n",
        "all_itemsets([\"ham\", \"cheese\", \"bread\"], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQIH_YVOUjAh",
        "outputId": "579b7f5f-e3c0-4b47-cc87-464d9743f5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ham', 'cheese'], ['ham', 'bread'], ['cheese', 'bread']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examing Our First Dataset\n"
      ],
      "metadata": {
        "id": "mSkoU6-ZDF3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. a) How many total records of movie ratings are there in entire dataset\n",
        "\n",
        "count = 0\n",
        "\n",
        "for txt in ['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt']:\n",
        "  with open(txt) as f:\n",
        "    for line in f:\n",
        "      if line.strip().endswith(\":\"):\n",
        "        continue\n",
        "      count += 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "id": "mu8Y9rm8DJmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbf24d1-00e4-4115-8f32-bb0967ae56dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100480507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. b) How many total unique users are there in entire dataset\n",
        "\n",
        "def find_unique_users(filenames):\n",
        "  user_set = set()\n",
        "\n",
        "  for txt in filenames:\n",
        "    with open(txt, \"r\") as f:\n",
        "      for line in f:\n",
        "        if len(line.split(\",\")) == 1:\n",
        "          continue\n",
        "        user_set.add(line.split(\",\")[0])\n",
        "\n",
        "  return len(user_set)\n",
        "\n",
        "find_unique_users(['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13NGD5V_jH_-",
        "outputId": "e51b49e9-3d0c-41b1-ba45-5ac03cadc95a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480189"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. c) What is the range of years that this data is valid over\n",
        "\n",
        "def find_range_years(filenames):\n",
        "  years = set()\n",
        "\n",
        "  for txt in filenames:\n",
        "    with open(txt, \"r\") as f:\n",
        "      for line in f:\n",
        "        if len(line.split(',')) == 3:\n",
        "          year = line.split(\",\")[2][0:4]\n",
        "          years.add(int(year))\n",
        "\n",
        "  return min(list(years)), max(list(years))\n",
        "\n",
        "min_year, max_year = find_range_years(['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt'])\n",
        "print(\"Range of years: \", min_year, \"to\", max_year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DayZf4JWjr_F",
        "outputId": "c96ba6e2-fd1c-445e-8fe5-0c503fdde174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Range of years:  1999 to 2005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. a) How many movies with unique names are there? That is to say, count the distinct names of the movies.\n",
        "\n",
        "import csv\n",
        "\n",
        "movie_set = set()\n",
        "\n",
        "with open('movie_titles.csv', encoding='iso-8859-1') as f:\n",
        "  lines = csv.reader(f)\n",
        "  for line in lines:\n",
        "    if len(line) >= 2:\n",
        "      movie = \" \".join(line[2:]).strip()\n",
        "    movie_set.add(movie)\n",
        "\n",
        "print(len(movie_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAy1w1eTxOIZ",
        "outputId": "1fe9b1f9-f4a1-4617-fdbf-96b523c9b6d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. b) How many movie names refer to four different movies?\n",
        "\n",
        "def refer_four_movies(filename):\n",
        "  movie_names_count = {}\n",
        "  res = 0\n",
        "\n",
        "  with open(filename, encoding='iso-8859-1') as f:\n",
        "    lines = csv.reader(f)\n",
        "\n",
        "    for line in lines:\n",
        "      if len(line) >= 2:\n",
        "        movie_name = \" \".join(line[2:]).strip()\n",
        "        if movie_name in movie_names_count:\n",
        "          movie_names_count[movie_name] += 1\n",
        "        else:\n",
        "          movie_names_count[movie_name] = 1\n",
        "\n",
        "    for movie, count in movie_names_count.items():\n",
        "      if count == 4:\n",
        "        res += 1\n",
        "\n",
        "  return res\n",
        "\n",
        "refer_four_movies('movie_titles.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA2WuJ3L5R21",
        "outputId": "0d5704fa-5e78-4a87-f70b-dedbf986b229"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. a) How many users rated exactly 200 movies?\n",
        "\n",
        "combined_data_list = ['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt']\n",
        "\n",
        "def count_exact_movies(files):\n",
        "  user_count = {}\n",
        "\n",
        "  for txt in combined_data_list:\n",
        "    with open(txt, \"r\") as f:\n",
        "      for line in f:\n",
        "        if len(line.split(\",\")) == 1:\n",
        "          continue\n",
        "        customer_id = int(line.split(\",\")[0])\n",
        "        if customer_id in user_count:\n",
        "          user_count[customer_id] += 1\n",
        "        else:\n",
        "          user_count[customer_id] = 1\n",
        "\n",
        "  return user_count\n",
        "\n",
        "user_count = count_exact_movies(combined_data_list)\n",
        "\n",
        "print(sum(v == 200 for v in user_count.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7TVbDao9G-P",
        "outputId": "50bb8ef4-3ac8-4aab-c441-8a94655d2c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. b) of these users, take the lowest user ID and print out the names of the movies that this person liked the most (all 5 star ratings).\n",
        "\n",
        "def find_lowest_user_id(user_count):\n",
        "  users = set()\n",
        "  for id, count in user_count.items():\n",
        "    if count == 200:\n",
        "      users.add(id)\n",
        "  return min(users)\n",
        "\n",
        "find_lowest_user_id(user_count)"
      ],
      "metadata": {
        "id": "95hppDJMFp4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42975b28-42c8-4492-9d4c-22574ecb6ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def find_movie_id_list(user_id):\n",
        "  customer_id_movies = defaultdict(set)\n",
        "\n",
        "  for i in range(1, 5):\n",
        "    with open(f'combined_data_{i}.txt', \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.rstrip()\n",
        "      if line.endswith(\":\"):\n",
        "        movie_id = int(line.split(\":\")[0])\n",
        "      row_data = line.split(\",\")\n",
        "      if len(row_data) == 3:\n",
        "        customer_id = int(row_data[0])\n",
        "        # rating\n",
        "        if int(row_data[1]) == 5:\n",
        "          customer_id_movies[customer_id].add(movie_id)\n",
        "  return customer_id_movies[user_id]"
      ],
      "metadata": {
        "id": "eA6BlIeJDq2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowest_user_id = find_lowest_user_id(user_count)\n",
        "movie_id_list = find_movie_id_list(lowest_user_id)\n",
        "print(movie_id_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL2PxVCQOTQI",
        "outputId": "50a74867-c154-4fb1-c26e-8d4085c6a8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{11521, 11907, 14601, 6029, 8846, 7057, 2452, 10774, 14358, 14999, 4633, 17174, 13856, 2465, 5538, 12195, 14240, 2342, 3371, 2862, 14382, 12084, 12852, 2743, 312, 571, 6974, 7230, 15296, 8387, 12870, 8904, 1865, 2122, 7755, 12232, 3917, 8782, 14671, 720, 3282, 6099, 12500, 14550, 9818, 16604, 17632, 5601, 17764, 5862, 15339, 494, 2158, 14961, 5237, 4727, 4345}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/movie_titles.csv\", encoding=\"latin1\", usecols=[1, 2], header=None, names=['year', 'movie']).shift()[1:]\n",
        "df.head(10)\n",
        "for movie_id in movie_id_list:\n",
        "  print(df['movie'][movie_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI0QNRcdRsmL",
        "outputId": "a74c7a98-2888-45c4-87a6-e1da97d85f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lord of the Rings: The Two Towers\n",
            "Cabaret\n",
            "Harold and Maude\n",
            "Amelie\n",
            "Election\n",
            "Lord of the Rings: The Two Towers: Extended Edition\n",
            "Lord of the Rings: The Fellowship of the Ring\n",
            "Taxi Driver\n",
            "Monty Python and the Holy Grail\n",
            "Monster\n",
            "Gandhi\n",
            "Maria Full of Grace\n",
            "Raging Bull\n",
            "This Is Spinal Tap\n",
            "Monty Python's Life of Brian\n",
            "The Accused\n",
            "Lord of the Rings: The Return of the King\n",
            "Super Size Me\n",
            "Whale Rider\n",
            "The Silence of the Lambs\n",
            "Raising Arizona\n",
            "Adaptation\n",
            "To Be and To Have\n",
            "The Pianist\n",
            "High Fidelity\n",
            "American Beauty\n",
            "The Usual Suspects\n",
            "The Lord of the Rings: The Fellowship of the Ring: Extended Edition\n",
            "Band of Brothers\n",
            "Minority Report\n",
            "Schindler's List\n",
            "Good Will Hunting\n",
            "Eternal Sunshine of the Spotless Mind\n",
            "Being John Malkovich\n",
            "Touching the Void\n",
            "Lost in Translation\n",
            "Garden State\n",
            "The Royal Tenenbaums\n",
            "Downfall\n",
            "Roger & Me\n",
            "Sideways\n",
            "Apocalypse Now\n",
            "Boys Don't Cry\n",
            "The Shawshank Redemption: Special Edition\n",
            "L.A. Confidential\n",
            "Unforgiven\n",
            "Days of Wine and Roses\n",
            "The Manchurian Candidate\n",
            "Shakespeare in Love\n",
            "Memento\n",
            "Three Kings\n",
            "Monty Python's The Meaning of Life: Special Edition\n",
            "Vietnam: A Television History\n",
            "Lord of the Rings: The Return of the King: Extended Edition\n",
            "To Die For\n",
            "Apocalypse Now Redux\n",
            "Bowling for Columbine\n"
          ]
        }
      ]
    }
  ]
}